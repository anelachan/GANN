# File: GANN.py
# Author: Anela Chan
# Purpose: Optimize architecture of a neural network via Genetic Algorithm.
# Finds the "best" vector representing number of nodes per each layer.

# Important notes: Has arbitrary max # of layers and nodes.
# Neural network in NN.py was preset to have 25 input nodes and 10 output node.

import random
import operator
from NN import *

# Note: these max number of layers and nodes per layer were set arbitrarily
MAX_NUM_LAYERS = 10
MAX_NODES_PER_LAYER = 100

# Binary string length follows from # of nodes and layers
BINARY_STRING_LENGTH = (len(bin(MAX_NODES_PER_LAYER))-2)*MAX_NUM_LAYERS

# Training file for getting accuracy
TRAINING_FILE = 'train.csv'

# Parameters for running genetic algorithm
default_options = {
	'population_size'		: 15,
	'crossover_points'	: [.3,.6],
	'mutation_rate'			: .05,
	'fitness_function'	: None,
	'num_generations'		: 3,
	'swap_rate'					: 0.2,
	'encoding'					: 'binary',
	'step_size'					: 2 # for integer vector encoding only
}

# Parameters for running neural network
nn_hidden_structure        = [10]
activation                 = 'tanh'
lmbda                      = 0.1
momentum                   = 0.0 
validation_data_size       = 0.2
learning_rate              = 0.01
num_epochs                 = 200000
show_confusion_matrix      = False
show_classification_report = False

# Load NN training data etc. to avoid extra I/O - will be used in get_accuracy
global_nn = NeuralNetwork(nn_hidden_structure,activation)
training_data = global_nn.load_training_data(TRAINING_FILE)
preprocessed_data_dict = global_nn.preprocess_training_data(training_data)
split_data_dict = global_nn.split_data(preprocessed_data_dict['X'], 
		preprocessed_data_dict['y'], validation_data_size)

# Returns accuracy from neural network
def get_accuracy(nn_hidden_structure,activation):
  nn = NeuralNetwork(nn_hidden_structure, activation)
  nn.train(split_data_dict['X_train'], split_data_dict['y_train'], \
  		learning_rate, num_epochs, momentum, lmbda)
  return nn.get_accuracy(split_data_dict['X_test'],split_data_dict['y_test'], \
		 show_confusion_matrix, show_classification_report)





# START INDIVIDUAL CLASS ------------------------------------------------------

# Individual class represents an individual in a population. 
class Individual(object):

	# Individual has phenotype, fitness function, fitness score
	def __init__ (self, vector, fitness_function):
		self.phenotype = vector
		self.phenotype = self.validate_vector(self.phenotype)
		self.fitness_function = fitness_function
		self.fitness_score = None

	# make sure no vectors w/ elements > MAX_NODES_PER_LAYER
	def validate_vector(self,vector):
		validated_vector = []
		for el in vector:
			if el > MAX_NODES_PER_LAYER:
				new_el = MAX_NODES_PER_LAYER
			else:
				new_el = el
			validated_vector.append(new_el)
		return validated_vector

	def get_fitness(self):
		return self.fitness_function(self.phenotype,activation)

	def get_phenotype(self):
		return self.phenotype

# END INDIVIDUAL CLASS ------------------------------------------------------



# START GENETIC ALGORITHM CLASS ---------------------------------------------

class GANN(object):

	def __init__(self, options=default_options):
		
		self.options = default_options
		self.options['fitness_function'] = get_accuracy
		for key in options.keys(): # because may not pass all keys
			self.options[key] = options[key]
	
		# this is the key object used for performing selection
		self.fitness_tuples = [] 

		# Initialize the population at t=0 - build array of Individual objects
		initial_population = [] # composed of Individual objects.
		for individual in range(0,self.options['population_size']):

			individual_arr = []
			num_layers = random.randint(1,MAX_NUM_LAYERS)
			for layer in range(0,num_layers):
				num_nodes = random.randint(1,MAX_NODES_PER_LAYER)
				individual_arr.append(num_nodes)
			if num_layers < MAX_NUM_LAYERS:
				for iteration in range(0,MAX_NUM_LAYERS-num_layers):
					individual_arr.append(0)
			# else it has already been filled

			new_individual = Individual( self.slice_vector(individual_arr), \
				self.options['fitness_function'] )
			initial_population.append( new_individual )

		# t = 0 find fitness for each autogenerated
		self.fitness_tuples = self.get_fitness_tuples( initial_population )




	# ENCODING AND DECODING ---------------------------------

	# Though this is "tied" to an Individual object it is actually dependent on
	# encoding chosen in GA. hence it lives in the GANN class.
	def get_genotype(self,indiv):
		if self.options['encoding'] == 'binary':
			genotype = str()
			for el in indiv.get_phenotype()[1:-1]:
				genotype += format(el,'07b')
			return genotype
		else:
			return indiv.get_phenotype()[1:-1]

	def parse_bitstring(self,genotype):
		num_chars = len(bin(MAX_NODES_PER_LAYER))-2
		return [genotype[i:i+num_chars] for i in range(0,len(genotype), num_chars)]

	def slice_vector(self, vector):
		try:
			return vector[:vector.index(0)] # SLICE OFF ZEROES
		except ValueError: # if no zero
			return vector

	def vector_from_bitstring(self,genotype):
		vector = [int(el,2) for el in self.parse_bitstring(genotype)]
		return self.slice_vector(vector)


	# END ENCODING AND DECODING METHODS -----------------------------------------



	# IMPORTANT FITNESS CALCULATING METHOD - MAIN COMPUTATION HERE --------------

	# Input: list of Individual OBJECTS
	# Output: list of tuples (genotype, score) for those individuals
	def get_fitness_tuples(self,individuals): 
		fitness_scores = [ indiv.get_fitness() for indiv in individuals ]
		list_of_genotypes = [ self.get_genotype(indiv) for indiv in individuals ] 
		fitness_tuples = zip(list_of_genotypes, fitness_scores)
		return fitness_tuples 
		# note: scores are NOT normalized bc they are just being sorted and sliced

	# END FITNESS CALCULATING METHOD --------------------------------------------



	# BEGIN NATURAL SELECTION METHODS -------------------------------------------

	# Input: None, but precondition - self.fitness_tuples is filled w/o nulls
	# Output: List of fitness tuples of those selected
	def select_for_crossover(self):
		# sort fitness tuples
		self.fitness_tuples = sorted(self.fitness_tuples, 
			key=operator.itemgetter(1),reverse=True)
		# will select POPULATION SIZE - NUMBER TO REPLACE
		slice_to = ( self.options['population_size'] - 
			int(self.options['swap_rate']*self.options['population_size']) )
		return self.fitness_tuples[ :slice_to ]

	# for reproduction between two parents
	def apply_crossover(self,genotype_1,genotype_2):
		crossover_points = [ int(el*self.options['population_size']) 
			for el in self.options['crossover_points']]
		new_genotype = (
			genotype_1[:crossover_points[0]]
			+ genotype_2[crossover_points[0]:crossover_points[1]]
			+ genotype_1[crossover_points[1]:]
		)
		return new_genotype


	# on one INDIVIDUAL offspring
	def apply_mutation(self,child_genotype):

		if self.options['encoding'] == 'binary':

			parsed_genotype = self.parse_bitstring(child_genotype)
			# only non-zero genes except the first one will be considered
			# remove trailing zeroes, except the first zero
			try:
				first_zero = parsed_genotype.index('0000000')
				genes_to_consider = parsed_genotype[:first_zero+1] 
			except ValueError: # if no zeroes
				genes_to_consider = parsed_genotype 

			new_child = str()
			for gene in genes_to_consider:
				for c in gene:
					if random.random() < self.options['mutation_rate']:
						if c == '0': 
							c = '1'
						elif c == '1':
							c = '0'
					new_child += c

			return new_child.ljust(BINARY_STRING_LENGTH,'0')

		# integer real-valued version
		else: 

			try:
				first_zero = child_genotype.index(0)
				genes_to_consider = child_genotype[:first_zero+1]
			except ValueError:
				genes_to_consider = child_genotype

			new_child = []
			for gene in genes_to_consider:
				if random.random() < self.options['mutation_rate']:
					gene += self.options['step_size']
				new_child.append(gene)
			return (new_child + [0]*MAX_NUM_LAYERS)[:MAX_NUM_LAYERS]


	# Input: a list of tuples representing (genotype, fitness)
	# Output: a list of Individual objects, the offspring of those selected
	# Purpose: Generate offspring, n = swap_rate*population_size
	def generate_offspring(self, selected): 

		num_to_generate = int(self.options['swap_rate'] * \
			self.options['population_size'])
		fitness_function = self.options['fitness_function']
		offspring = []

		for iteration in range(0,num_to_generate):
			# select 2 parents randomly
			parent_1 = random.choice( selected )
			
			if self.options['encoding'] == 'binary':
				parent_2 = random.choice( list( set(selected) - set( (parent_1) ) ) )
			else: 
				parent_2 = random.choice( selected ) 

			# breed and mutate
			child = self.apply_crossover(parent_1[0],parent_2[0])
			offspring.append(self.apply_mutation(child))

		# convert offspring to Individual objects
		if self.options['encoding'] == 'binary':
			offspring = [Individual(self.vector_from_bitstring(child),
				fitness_function) for child in offspring]
		else:
			offspring = [Individual(child,fitness_function) 
				for child in offspring]
		return offspring



	# Purpose: run a cycle of selection, generating offspring crossover/mutation, 
	# replacing part of the populaiton
	def evolve(self):
		# select fitter individuals for mating
		selected = self.select_for_crossover() 

		# generate offspring - these will replace the weaker individuals
		offspring = self.generate_offspring( selected )

		# get fitness tuples on offspring 
		offspring_fitness_tuples = self.get_fitness_tuples( offspring )

		# replace weaker individuals, fitness tuples already calculated above
		num_to_replace = len(offspring)
		self.fitness_tuples = (self.fitness_tuples[: \
			(self.options['population_size']- num_to_replace)] \
			+ offspring_fitness_tuples)

	def get_final_genotype(self):
		# sort fitness tuples, find best
		self.fitness_tuples = sorted(self.fitness_tuples, 
			key=operator.itemgetter(1),reverse=True)
		genotypes = [el[0] for el in self.fitness_tuples]
		best = genotypes[0]

		if self.options['encoding'] == 'binary':
			return self.vector_from_bitstring(best)
		else:
			return best[:best.index(0)]

	def run(self):
		for generation in range(0,self.options['num_generations']):
			self.evolve()
			fitness_scores = [ el[1] for el in self.fitness_tuples ]
		print 'Final accuracy score: %s' % max(fitness_scores)
		best_vector = self.get_final_genotype()
		print 'Best vector: %s' % best_vector
		return best_vector

# END GENETIC ALGORITHM CLASS ------------------------------------------------		


def main():

	x = GANN()
	x.run()
	


if __name__ == '__main__':
	main()


